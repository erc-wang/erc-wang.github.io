<!DOCTYPE html>
<html>
<head>
    <title>My Portfolio</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
    </style>
</head>
<body>
    <h1>Project 5: Fun with Diffusion Models!</h1>
    <h3>About</h3>
    <p>This project is split into two parts with the first one covering usage of diffusion models and how to manipulate denoising processes to get results we want. The second part covers UNets and how to initialize their structure and models to denoise images.</p>
    <h1>Part A</h2>  
    <h3>Using Precomputed Text Embeddings</h3>
    <p>DeepFloyd is a text-to-image model that generates images based on text prompts. The prompt "a high quality photo" is used as a neutral, unconditional input, allowing the model to generate random images without specific guidance.</p>
    <p>This helps the model apply the diffusion process to transform noisy images into realistic ones. We also provide conditional inputs, which help determine the contents of the image that are generated.</p>
    <p>For this project I used seed = 3898</p>
    <p>The images below were generated, with their caption as their prompt and differing num_inferences.</p>
    <p>Stage 1 with num_inference_steps=20:</p>
    <table>
      <tr>
        <td>
          <img src="output/A/0a.png" width="256" height="256">
          <p>an oil painting of a snowy mountain village</p>
        </td>
        <td>
          <img src="output/A/0b.png" width="256" height="256">
          <p>a man wearing a hat</p>
        </td>
        <td>
          <img src="output/A/0c.png" width="256" height="256">
          <p>a rocket ship</p>
        </td>
      </tr>
    </table>
    <p>Stage 2 with num_inference_steps=20:</p>
    <table>
      <tr>
        <td>
          <img src="output/A/0d.png" width="256" height="256">
          <p>an oil painting of a snowy mountain village</p>
        </td>
        <td>
          <img src="output/A/0e.png" width="256" height="256">
          <p>a man wearing a hat</p>
        </td>
        <td>
          <img src="output/A/0f.png" width="256" height="256">
          <p>a rocket ship</p>
        </td>
      </tr>
    </table>
    <p>Stage 1 with num_inference_steps=10:</p>
    <table>
      <tr>
        <td>
          <img src="output/A/0g.png" width="256" height="256">
          <p>an oil painting of a snowy mountain village</p>
        </td>
        <td>
          <img src="output/A/0h.png" width="256" height="256">
          <p>a man wearing a hat</p>
        </td>
        <td>
          <img src="output/A/0i.png" width="256" height="256">
          <p>a rocket ship</p>
        </td>
      </tr>
    </table>
    <p>Stage 1 with num_inference_steps=30:</p>
    <table>
      <tr>
        <td>
          <img src="output/A/0j.png" width="256" height="256">
          <p>an oil painting of a snowy mountain village</p>
        </td>
        <td>
          <img src="output/A/0k.png" width="256" height="256">
          <p>a man wearing a hat</p>
        </td>
        <td>
          <img src="output/A/0l.png" width="256" height="256">
          <p>a rocket ship</p>
        </td>
      </tr>
    </table>
    <p>It is worth mentioning that every image has been upscaled to 256x256 when every stage 1 output is actually 64x64. For later parts of this project, all outputs will be originally 64x64.</p>
    <p>When num_inference_steps increases, the edges become more defined and the finer details can be made out. When num_inference_steps is lower, there is largely more visible amount of blurring.</p>
    <h3>Sampling Loops</h3>
    <p>In a diffusion model, we can start with a clean image and progressively add noise over time until it becomes pure noise. The model reverses this process by predicting and removing the noise, gradually denoising the image. </p> 
    <p>We can also generate images, by starting with pure noise and iteratively removing it, refining the image step by step until a clean image appears. We can manipulate the amount of noise that is added to each step.</p>
    <h3>Implementing the Forward Process</h3>
    <p>The forward process entails of noising an image from a Gaussian distribution with a specific mean and variance at each timestep.</p>
    <p>The variable alphas_cumprod tracks the noise level, where smaller t values correspond to cleaner images, and larger t values indicate more noise.</p>
    <p>The function forward(im, t) depicts the image im at step t.</p>
    <table>
      <tr>
        <td>
          <img src="output/A/campanile.png" width="256" height="256">
          <p>Berkeley Campanile</p>
        </td>
        <td>
          <img src="output/A/11a.png" width="256" height="256">
          <p>Noisy Campanile at t=250</p>
        </td>
        <td>
          <img src="output/A/11b.png" width="256" height="256">
          <p>Noisy Campanile at t=500</p>
        </td>
        <td>
          <img src="output/A/11c.png" width="256" height="256">
          <p>Noisy Campanile at t=750</p>
        </td>
      </tr>
    </table>
    
</body>
</html>
